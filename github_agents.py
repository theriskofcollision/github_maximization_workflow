import os
import yaml
import logging
import requests
from typing import List, Dict, Optional, Callable
from collections import deque

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("GitHubAgents")

# --- Event Bus ---
class Event:
    def __init__(self, type: str, payload: Dict):
        self.type = type
        self.payload = payload

class EventBus:
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.event_queue = deque()

    def subscribe(self, event_type: str, handler: Callable):
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(handler)

    def publish(self, event: Event):
        logger.info(f"[EventBus] Event Published: {event.type}")
        self.event_queue.append(event)

    def process_events(self):
        while self.event_queue:
            event = self.event_queue.popleft()
            if event.type in self.subscribers:
                for handler in self.subscribers[event.type]:
                    handler(event)

# --- Agents ---
class Agent:
    def __init__(self, name: str, role: str, goal: str, system_prompt: str, event_bus: EventBus = None):
        self.name = name
        self.role = role
        self.goal = goal
        self.system_prompt = system_prompt
        self.event_bus = event_bus

    def run(self, task: str, context: Dict = None) -> str:
        """
        Executes the agent's task using Google Gemini.
        """
        logger.info(f"[{self.name}] Starting task: {task}")
        
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            logger.warning("GEMINI_API_KEY not found. Running in simulation mode.")
            return f"[{self.name}] Completed task: {task}. (Simulation - No API Key)"

        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-pro')
            
            prompt = f"""
            System: {self.system_prompt}
            Role: {self.role}
            Goal: {self.goal}
            Context: {context if context else {}}
            Task: {task}
            """
            
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Error calling Gemini API: {e}")
            return f"Error: {e}"

class RepoGardener(Agent):
    def audit_repo(self, repo_path: str):
        logger.info(f"Auditing repo at {repo_path}...")
        # Logic to check for README, LICENSE, etc.
        if not os.path.exists(os.path.join(repo_path, "README.md")):
            logger.warning(f"Missing README in {repo_path}")
            if self.event_bus:
                self.event_bus.publish(Event("MISSING_FILE", {"repo": repo_path, "file": "README.md"}))
            return "Missing README"
        return "Repo looks healthy"

    def audit_repo_api(self, repo_name: str, check_file_exists_api_func: Callable):
        logger.info(f"Auditing {repo_name}...")
        if not check_file_exists_api_func(repo_name, "README.md"):
             logger.warning(f"Missing README in {repo_name}")
             if self.event_bus:
                 self.event_bus.publish(Event("MISSING_FILE", {"repo": repo_name, "file": "README.md", "is_remote": True}))
        else:
            logger.info(f"{repo_name} is healthy.")

class CodeArchitect(Agent):
    def scaffold_project(self, project_name: str, stack: str):
        logger.info(f"Scaffolding {project_name} with {stack}...")
        # Logic to create directories and files
        os.makedirs(project_name, exist_ok=True)
        with open(f"{project_name}/README.md", "w") as f:
            f.write(f"# {project_name}\n\nGenerated by CodeArchitect.")
        return f"Project {project_name} created."

    def handle_missing_file(self, event: Event):
        repo = event.payload['repo']
        file = event.payload['file']
        logger.info(f"[{self.name}] Handling MISSING_FILE: {file} in {repo}")
        
        # Generate content using LLM
        content = self.run(f"Generate a professional {file} for the repository {repo}.")
        logger.info(f"[{self.name}] Generated content for {file}:\n{content[:100]}...")
        
        # In a real scenario, we would commit this file back to the repo via API
        # For now, we just log the generation
        logger.info(f"[{self.name}] (Simulation) Would commit {file} to {repo}")

class TrendSurfer(Agent):
    def find_trends(self, topics: List[str]):
        logger.info(f"Scanning trends for: {topics}")
        # Logic to scrape or query GitHub API
        return ["https://github.com/example/trending-repo"]

class ProfilePolisher(Agent):
    def update_profile(self, stats: Dict):
        logger.info(f"Updating profile with stats: {stats}")
        # Logic to update README.md
        return "Profile updated."

def load_config(config_path: str) -> Dict:
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    config = load_config("workflow_config.yml")
    logger.info(f"Starting {config['project_name']}...")

    # Initialize Event Bus
    event_bus = EventBus()

    # Initialize Agents
    gardener = RepoGardener("RepoGardener", "Maintainer", "Keep repos healthy", "...", event_bus)
    architect = CodeArchitect("CodeArchitect", "Builder", "Scaffold projects", "...", event_bus)
    surfer = TrendSurfer("TrendSurfer", "Scout", "Find trends", "...", event_bus)
    polisher = ProfilePolisher("ProfilePolisher", "Brand Manager", "Polish profile", "...", event_bus)

    # Register Event Handlers
    event_bus.subscribe("MISSING_FILE", architect.handle_missing_file)

    # GitHub API Helper
    def get_github_headers():
        token = os.getenv("GH_PAT") or os.getenv("GITHUB_TOKEN")
        if not token:
            raise ValueError("No GitHub token found. Please set GH_PAT or GITHUB_TOKEN.")
        return {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github.v3+json"}

    def fetch_repos(scope: str = "all") -> List[Dict]:
        headers = get_github_headers()
        repos = []
        
        if scope == "current":
            pass 
        
        # Fetch all repos for the authenticated user
        url = "https://api.github.com/user/repos?per_page=100&type=all"
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            repos = response.json()
        except Exception as e:
            logger.error(f"Failed to fetch repos: {e}")
            
        return repos

    def check_file_exists_api(repo_full_name: str, file_path: str) -> bool:
        headers = get_github_headers()
        url = f"https://api.github.com/repos/{repo_full_name}/contents/{file_path}"
        response = requests.get(url, headers=headers)
        return response.status_code == 200

    # Workflow Execution
    if config['agents']['repo_gardener']['enabled']:
        scope = config['agents']['repo_gardener'].get('audit_scope', 'current')
        
        if scope == 'all':
            logger.info("Fetching all repositories...")
            repos = fetch_repos()
            for repo in repos:
                repo_name = repo['full_name']
                gardener.audit_repo_api(repo_name, check_file_exists_api)
        else:
            # Fallback to local check for current repo
            gardener.audit_repo(".")

    if config['agents']['trend_surfer']['enabled']:
        trends = surfer.find_trends(config['agents']['trend_surfer']['topics'])
        logger.info(f"Found trends: {trends}")

    # Process Event Queue
    logger.info("Processing Event Queue...")
    event_bus.process_events()

    logger.info("Workflow completed.")

if __name__ == "__main__":
    main()
