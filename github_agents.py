import os
import yaml
import logging
import requests
from typing import List, Dict, Optional, Callable
from collections import deque

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("GitHubAgents")

# --- Event Bus ---
class Event:
    def __init__(self, type: str, payload: Dict):
        self.type = type
        self.payload = payload

class EventBus:
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.event_queue = deque()

    def subscribe(self, event_type: str, handler: Callable):
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(handler)

    def publish(self, event: Event):
        logger.info(f"[EventBus] Event Published: {event.type}")
        self.event_queue.append(event)

    def process_events(self):
        while self.event_queue:
            event = self.event_queue.popleft()
            if event.type in self.subscribers:
                for handler in self.subscribers[event.type]:
                    handler(event)

# --- Agents ---
class Agent:
    def __init__(self, name: str, role: str, goal: str, system_prompt: str, event_bus: EventBus = None):
        self.name = name
        self.role = role
        self.goal = goal
        self.system_prompt = system_prompt
        self.event_bus = event_bus

    def run(self, task: str, context: Dict = None) -> str:
        """
        Executes the agent's task using Google Gemini.
        """
        logger.info(f"[{self.name}] Starting task: {task}")
        
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            logger.warning("GEMINI_API_KEY not found. Running in simulation mode.")
            return f"[{self.name}] Completed task: {task}. (Simulation - No API Key)"

        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-2.0-flash')
            
            prompt = f"""
            System: {self.system_prompt}
            Role: {self.role}
            Goal: {self.goal}
            Context: {context if context else {}}
            Task: {task}
            """
            
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Error calling Gemini API: {e}")
            return f"Error: {e}"

class RepoGardener(Agent):
    def audit_repo(self, repo_path: str):
        logger.info(f"Auditing repo at {repo_path}...")
        # Logic to check for README, LICENSE, etc.
        if not os.path.exists(os.path.join(repo_path, "README.md")):
            logger.warning(f"Missing README in {repo_path}")
            if self.event_bus:
                self.event_bus.publish(Event("MISSING_FILE", {"repo": repo_path, "file": "README.md"}))
            return "Missing README"
        return "Repo looks healthy"

    def audit_repo_api(self, repo_name: str, check_file_exists_api_func: Callable, check_workflow_status_func: Callable):
        logger.info(f"Auditing {repo_name}...")
        
        # 1. Check for README
        if not check_file_exists_api_func(repo_name, "README.md"):
             logger.warning(f"Missing README in {repo_name}")
             if self.event_bus:
                 self.event_bus.publish(Event("MISSING_FILE", {"repo": repo_name, "file": "README.md", "is_remote": True}))
        
        # 2. Check Workflow Status
        workflow_error = check_workflow_status_func(repo_name)
        if workflow_error:
            logger.error(f"Workflow Failure in {repo_name}: {workflow_error}")
            # Future: Publish WORKFLOW_FAILED event
        
        if not workflow_error and check_file_exists_api_func(repo_name, "README.md"):
            logger.info(f"{repo_name} is healthy.")

class CodeArchitect(Agent):
    def scaffold_project(self, project_name: str, stack: str):
        logger.info(f"Scaffolding {project_name} with {stack}...")
        # Logic to create directories and files
        os.makedirs(project_name, exist_ok=True)
        with open(f"{project_name}/README.md", "w") as f:
            f.write(f"# {project_name}\n\nGenerated by CodeArchitect.")
        return f"Project {project_name} created."

    def handle_missing_file(self, event: Event):
        repo = event.payload['repo']
        file = event.payload['file']
        logger.info(f"[{self.name}] Handling MISSING_FILE: {file} in {repo}")
        
        # Generate content using LLM
        prompt = f"Generate a professional {file} for the repository {repo}. IMPORTANT: Output ONLY the raw file content. Do not include any conversational text, 'Here is the file', or markdown code fences (```). Start directly with the file content."
        content = self.run(prompt)
        
        # Clean up the response (remove markdown fences if present)
        if content.startswith("```"):
            content = content.split("\n", 1)[1]
            if content.endswith("```"):
                content = content.rsplit("\n", 1)[0]
        
        # Remove any leading conversational text if it doesn't look like a file start
        # Simple heuristic: If it doesn't start with # or < or import or package, and has a double newline, split it.
        # But the prompt engineering above should handle most cases.
        
        logger.info(f"[{self.name}] Generated content for {file}:\n{content[:100]}...")
        
        # Commit to GitHub
        try:
            commit_url = self.commit_file_to_github(repo, file, content, f"Create {file} via CodeArchitect Agent")
            logger.info(f"[{self.name}] Successfully committed {file} to {repo}. URL: {commit_url}")
        except Exception as e:
            logger.error(f"[{self.name}] Failed to commit {file}: {e}")

    def commit_file_to_github(self, repo_full_name: str, file_path: str, content: str, commit_message: str) -> str:
        """
        Commits a file to a GitHub repository using the API.
        """
        token = os.getenv("GH_PAT") or os.getenv("GITHUB_TOKEN")
        if not token:
            raise ValueError("No GitHub token found.")
            
        headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        url = f"https://api.github.com/repos/{repo_full_name}/contents/{file_path}"
        
        # Check if file exists to get SHA (for updates)
        sha = None
        try:
            get_response = requests.get(url, headers=headers)
            if get_response.status_code == 200:
                sha = get_response.json()['sha']
        except Exception:
            pass

        import base64
        content_b64 = base64.b64encode(content.encode('utf-8')).decode('utf-8')
        
        data = {
            "message": commit_message,
            "content": content_b64
        }
        if sha:
            data["sha"] = sha
            
        response = requests.put(url, headers=headers, json=data)
        response.raise_for_status()
        return response.json()['content']['html_url']

class TrendSurfer(Agent):
    def find_trends(self, topics: List[str]):
        logger.info(f"Scanning trends for: {topics}")
        # Logic to scrape or query GitHub API
        return ["https://github.com/example/trending-repo"]

class ProfilePolisher(Agent):
    def update_profile(self, stats: Dict):
        logger.info(f"Updating profile with stats: {stats}")
        # Logic to update README.md
        return "Profile updated."

def load_config(config_path: str) -> Dict:
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def main():
    config = load_config("workflow_config.yml")
    logger.info(f"Starting {config['project_name']}...")

    # Initialize Event Bus
    event_bus = EventBus()

    # Initialize Agents
    gardener = RepoGardener("RepoGardener", "Maintainer", "Keep repos healthy", "...", event_bus)
    architect = CodeArchitect("CodeArchitect", "Builder", "Scaffold projects", "...", event_bus)
    surfer = TrendSurfer("TrendSurfer", "Scout", "Find trends", "...", event_bus)
    polisher = ProfilePolisher("ProfilePolisher", "Brand Manager", "Polish profile", "...", event_bus)

    # Register Event Handlers
    event_bus.subscribe("MISSING_FILE", architect.handle_missing_file)

    # GitHub API Helper
    def get_github_headers():
        token = os.getenv("GH_PAT") or os.getenv("GITHUB_TOKEN")
        if not token:
            raise ValueError("No GitHub token found. Please set GH_PAT or GITHUB_TOKEN.")
        return {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github.v3+json"}

    def fetch_repos(scope: str = "all") -> List[Dict]:
        headers = get_github_headers()
        repos = []
        
        if scope == "current":
            pass 
        
        # Fetch all repos for the authenticated user
        url = "https://api.github.com/user/repos?per_page=100&type=all"
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            repos = response.json()
        except Exception as e:
            logger.error(f"Failed to fetch repos: {e}")
            
        return repos

    def check_workflow_status(repo_full_name: str) -> Optional[str]:
        headers = get_github_headers()
        # Fetch the latest run (per_page=1 implies latest because default sort is created_at desc)
        url = f"https://api.github.com/repos/{repo_full_name}/actions/runs?per_page=1"
        try:
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                data = response.json()
                if data['total_count'] > 0:
                    latest_run = data['workflow_runs'][0]
                    if latest_run['conclusion'] == 'failure':
                        return f"Run #{latest_run['run_number']} ({latest_run['name']}) failed. URL: {latest_run['html_url']}"
        except Exception as e:
            logger.error(f"Failed to check workflows for {repo_full_name}: {e}")
        return None

    # Workflow Execution
    if config['agents']['repo_gardener']['enabled']:
        scope = config['agents']['repo_gardener'].get('audit_scope', 'current')
        
        if scope == 'all':
            logger.info("Fetching all repositories...")
            repos = fetch_repos()
            for repo in repos:
                repo_name = repo['full_name']
                gardener.audit_repo_api(repo_name, check_file_exists_api, check_workflow_status)
        else:
            # Fallback to local check for current repo
            gardener.audit_repo(".")

    if config['agents']['trend_surfer']['enabled']:
        trends = surfer.find_trends(config['agents']['trend_surfer']['topics'])
        logger.info(f"Found trends: {trends}")

    # Process Event Queue
    logger.info("Processing Event Queue...")
    event_bus.process_events()

    logger.info("Workflow completed.")

if __name__ == "__main__":
    main()
